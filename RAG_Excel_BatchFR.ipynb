{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94081d1",
   "metadata": {},
   "source": [
    "# üìä RAG System - Batch Excel Processing\n",
    "\n",
    "## Automated Question Answering from Company Documents\n",
    "\n",
    "This notebook demonstrates how to build a complete RAG (Retrieval-Augmented Generation) system that:\n",
    "- Loads PDF documents\n",
    "- Processes questions from an Excel file\n",
    "- Answers each question using AI\n",
    "- Saves all responses back to Excel\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Step 1: Install Required Libraries\n",
    "\n",
    "Think of this like gathering all your tools before starting a project!\n",
    "\n",
    "### What are we doing here?\n",
    "\n",
    "Before we start, we need to install all the tools (libraries) that Python will use to:- Work with Excel files\n",
    "\n",
    "- Read PDF files- Talk to the AI model\n",
    "\n",
    "- Convert text into numbers (embeddings)- Store information in a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60e2ef23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./.venv/lib/python3.12/site-packages (1.2.4)\n",
      "Requirement already satisfied: langchain-text-splitters in ./.venv/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-community in ./.venv/lib/python3.12/site-packages (0.4.1)\n",
      "Requirement already satisfied: chromadb in ./.venv/lib/python3.12/site-packages (1.4.0)\n",
      "Requirement already satisfied: pypdf in ./.venv/lib/python3.12/site-packages (6.5.0)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.12/site-packages (2.15.0)\n",
      "Requirement already satisfied: sentence-transformers in ./.venv/lib/python3.12/site-packages (5.2.0)\n",
      "Requirement already satisfied: tiktoken in ./.venv/lib/python3.12/site-packages (0.12.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: openpyxl in ./.venv/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in ./.venv/lib/python3.12/site-packages (from langchain) (1.2.7)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in ./.venv/lib/python3.12/site-packages (from langchain) (1.0.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.12/site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in ./.venv/lib/python3.12/site-packages (from langchain-community) (2.0.45)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in ./.venv/lib/python3.12/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in ./.venv/lib/python3.12/site-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.12/site-packages (from langchain-community) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in ./.venv/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in ./.venv/lib/python3.12/site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in ./.venv/lib/python3.12/site-packages (from langchain-community) (0.6.4)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in ./.venv/lib/python3.12/site-packages (from langchain-community) (2.4.0)\n",
      "Requirement already satisfied: build>=1.0.3 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.4.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.40.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (4.15.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./.venv/lib/python3.12/site-packages (from chromadb) (0.22.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./.venv/lib/python3.12/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./.venv/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in ./.venv/lib/python3.12/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./.venv/lib/python3.12/site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (0.21.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (34.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./.venv/lib/python3.12/site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./.venv/lib/python3.12/site-packages (from chromadb) (3.11.5)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in ./.venv/lib/python3.12/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (1.8.0)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.12/site-packages (from tiktoken) (2025.11.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: et-xmlfile in ./.venv/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: packaging>=19.1 in ./.venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Requirement already satisfied: pyproject_hooks in ./.venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.45.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.13.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in ./.venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in ./.venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.6)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: coloredlogs in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in ./.venv/lib/python3.12/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./.venv/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./.venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: joblib>=1.3.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in ./.venv/lib/python3.12/site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.12/site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./.venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries for RAG system\n",
    "!pip install langchain langchain-text-splitters langchain-community chromadb pypdf openai sentence-transformers tiktoken pandas openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3b11e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Step 2: Verify Installation\n",
    "\n",
    "If you see \"All libraries installed successfully!\", you're good to go! üéâ\n",
    "\n",
    "### What are we doing here?\n",
    "Let's make sure everything installed correctly! We'll import some of the main libraries and see if Python can find them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c2d075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Verify installation\n",
    "import langchain\n",
    "import chromadb\n",
    "import pandas as pd\n",
    "\n",
    "print(\"All libraries installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca42cef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÑ Step 3: Load PDF Document\n",
    "\n",
    "This is like taking a book and separating it into individual pages so we can work with them!\n",
    "\n",
    "### What are we doing here?\n",
    "\n",
    "Now we're going to read the PDF file with all the company policies. The PDF loader will:3. Store each page as a separate \"document\"\n",
    "\n",
    "1. Open the PDF file2. Extract the text from each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b202fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/RAG Course Enhaced/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF: Company Policies.pdf\n",
      "Pages loaded: 8\n",
      "\n",
      "Total pages: 8\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load the PDF file\n",
    "pdf_path = \"/home/user/RAG Course Enhaced/Docs/Company Policies.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "# Load all pages\n",
    "pages = loader.load()\n",
    "\n",
    "# Show how many pages were loaded\n",
    "print(f\"PDF: Company Policies.pdf\")\n",
    "print(f\"Pages loaded: {len(pages)}\")\n",
    "print(f\"\\nTotal pages: {len(pages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec38ed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÇÔ∏è Step 4: Split Text into Chunks\n",
    "\n",
    "Think of it like cutting a pizza into slices - easier to handle!\n",
    "\n",
    "### What are we doing here?\n",
    "\n",
    "Each page might be too long for the AI to process efficiently. So we'll cut them into smaller pieces called \"chunks\".- We use overlap (50 characters) so important information doesn't get cut in half\n",
    "\n",
    "- Smaller chunks = more precise search results\n",
    "\n",
    "**Why?**- Embedding models have limits on how much text they can handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d5bc5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original pages: 8\n",
      "Chunks created: 32\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "# Split the documents into chunks\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "\n",
    "# Show results\n",
    "print(f\"Original pages: {len(pages)}\")\n",
    "print(f\"Chunks created: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbad2d32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßÆ Step 5: Create Embedding Function\n",
    "\n",
    "### What are we doing here?\n",
    "\n",
    "This is where the magic starts! We're creating a special tool that converts text into numbers (embeddings).‚ö†Ô∏è Make sure LM Studio is running with the nomic-embed-text model loaded!\n",
    "\n",
    "\n",
    "\n",
    "**What are embeddings?**We need a special version that works with LM Studio (our local AI server).\n",
    "\n",
    "- They're lists of numbers that represent the \"meaning\" of text**Why this custom class?**\n",
    "\n",
    "- Similar texts have similar numbers\n",
    "- This lets the computer understand which chunks are related to a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce15797e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimensions: 768\n",
      "Embeddings working!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "class LMStudioEmbeddings(Embeddings):\n",
    "    def __init__(self, base_url=\"http://localhost:1234\", model=\"nomic-embed-text-v1.5\"):\n",
    "        self.base_url = base_url\n",
    "        self.model = model\n",
    "    \n",
    "    def embed_documents(self, texts):\n",
    "        \"\"\"Embed a list of documents\"\"\"\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/v1/embeddings\",\n",
    "                json={\"input\": text, \"model\": self.model}\n",
    "            )\n",
    "            embedding = response.json()[\"data\"][0][\"embedding\"]\n",
    "            embeddings.append(embedding)\n",
    "        return embeddings\n",
    "    \n",
    "    def embed_query(self, text):\n",
    "        \"\"\"Embed a single query\"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.base_url}/v1/embeddings\",\n",
    "            json={\"input\": text, \"model\": self.model}\n",
    "        )\n",
    "        return response.json()[\"data\"][0][\"embedding\"]\n",
    "\n",
    "# Create the embeddings instance\n",
    "embeddings = LMStudioEmbeddings()\n",
    "\n",
    "# Test it\n",
    "test_embedding = embeddings.embed_query(\"Hello world\")\n",
    "print(f\"Embedding dimensions: {len(test_embedding)}\")\n",
    "print(\"Embeddings working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eab1d9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üóÑÔ∏è Step 6: Create Vector Database\n",
    "\n",
    "### What are we doing here?\n",
    "\n",
    "Now we'll create a special database that stores all our chunks AND their embeddings together.üí° This step might take a minute - it's processing all your document chunks!\n",
    "\n",
    "\n",
    "\n",
    "**What happens here:**It's designed specifically for finding similar text quickly using embeddings!\n",
    "\n",
    "1. Takes each chunk of text**Why ChromaDB?**\n",
    "\n",
    "2. Converts it to embeddings (numbers)\n",
    "\n",
    "3. Saves both the text and numbers in ChromaDB4. Creates an index for super-fast searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e951f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database created with 32 documents\n",
      "Saved to 'excel_database' folder\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Create vector database from chunks and save to disk\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"excel_database\"\n",
    ")\n",
    "\n",
    "print(f\"Vector database created with {vectorstore._collection.count()} documents\")\n",
    "print(\"Saved to 'excel_database' folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29de9a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîå Step 7: Connect to LM Studio\n",
    "\n",
    "### What are we doing here?\n",
    "\n",
    "Time to connect to the brain of our system - the Large Language Model (LLM)!‚ö†Ô∏è Make sure LM Studio is running with a model loaded before running this!\n",
    "\n",
    "\n",
    "\n",
    "**What's LM Studio?**3. If it responds, we're ready to go!\n",
    "\n",
    "It's a program running on your computer that hosts AI models locally (no internet needed!).2. We test it with a simple message\n",
    "\n",
    "1. We create a connection to LM Studio at http://127.0.0.1:1234\n",
    "**What happens here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2beb9121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am currently working on a project for my boss. It's a big presentation that I need to finish by the end of the day. \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Connect to LM Studio\n",
    "client = OpenAI(\n",
    "    base_url=\"http://127.0.0.1:1234/v1\",\n",
    "    api_key=\"not-needed\"\n",
    ")\n",
    "\n",
    "# Test with a simple message\n",
    "response = client.chat.completions.create(\n",
    "    model=\"local-model\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, are you working?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb21426a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîó Step 8: Build RAG Pipeline Functions\n",
    "\n",
    "### What are we doing here?\n",
    "\n",
    "This is the core of our RAG system! We're creating 3 functions that work together:Then we test it with a sample question!\n",
    "\n",
    "\n",
    "\n",
    "**1. create_augmented_prompt()**  - **G**eneration: Get the answer\n",
    "\n",
    "- Takes the question + relevant documents  - **A**ugmentation: Build the prompt\n",
    "\n",
    "- Combines them into one prompt for the AI  - **R**etrieval: Search for relevant chunks\n",
    "\n",
    "- This is the \"Augmentation\" part of RAG- The complete workflow:\n",
    "\n",
    "**3. rag_pipeline()**\n",
    "\n",
    "**2. get_response()**\n",
    "\n",
    "- Sends the prompt to the LLM- This is the \"Generation\" part of RAG\n",
    "- Gets back the AI's answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb2a1444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the vacation policy?\n",
      "\n",
      "Answer: \n",
      "Based on the information provided in the context, the vacation policy for full-time employees at the company is as follows:\n",
      "\"Full-time employees are entitled to paid annual leave based on their length of service. Leave accrual begins from the first day of employment.\"\n",
      "This means that full-time employees are eligible to receive paid annual leave based on the length of time they have been employed with the company, and they begin to accrue leave hours from their first day of work. The policy also requires employees to submit leave requests through the appropriate system and obtain approval from their supervisor before taking time off.\n"
     ]
    }
   ],
   "source": [
    "def create_augmented_prompt(question, documents):\n",
    "    \"\"\"Combine retrieved documents with the question\"\"\"\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "    \n",
    "    prompt = f\"\"\"Use the following context to answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def get_response(client, prompt):\n",
    "    \"\"\"Send prompt to LLM and return response\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"local-model\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def rag_pipeline(question, database, client):\n",
    "    \"\"\"Complete RAG workflow: retrieve, augment, generate\"\"\"\n",
    "    # Step 1: Retrieve relevant documents\n",
    "    documents = database.similarity_search(question, k=3)\n",
    "    \n",
    "    # Step 2: Create augmented prompt\n",
    "    prompt = create_augmented_prompt(question, documents)\n",
    "    \n",
    "    # Step 3: Get response from LLM\n",
    "    answer = get_response(client, prompt)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "\n",
    "# Test the RAG pipeline\n",
    "question = \"What is the vacation policy?\"\n",
    "answer = rag_pipeline(question, vectorstore, client)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"\\nAnswer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40455ad7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Step 9: Load Excel File with Questions\n",
    "\n",
    "### What are we doing here?\n",
    "\n",
    "Now we'll load the Excel file with all the employee questions!This helps us understand what we're working with before processing!\n",
    "\n",
    "\n",
    "\n",
    "**The Excel should have these columns:**3. Displays the first few rows so we can see the data\n",
    "\n",
    "- **Column A**: Employee name2. Shows us how many questions we have\n",
    "\n",
    "- **Column B**: Their question1. Pandas reads the Excel file\n",
    "\n",
    "- **Column C**: Answer (empty for now - we'll fill it!)**What happens:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5da08e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 5\n",
      "Columns: ['Worker', 'Question', 'Agent Answer']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Worker</th>\n",
       "      <th>Question</th>\n",
       "      <th>Agent Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sarah Mitchell</td>\n",
       "      <td>How many days of annual leave am I entitled to...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David Rodriguez</td>\n",
       "      <td>What should I do if I need to work from home? ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emily Chen</td>\n",
       "      <td>If a close family member passes away, how many...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marcus Jhonson</td>\n",
       "      <td>What happens if I report to work late multiple...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jennifer Thompson</td>\n",
       "      <td>Can I accept gifts from clients or vendors, or...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Worker                                           Question  \\\n",
       "0     Sarah Mitchell  How many days of annual leave am I entitled to...   \n",
       "1    David Rodriguez  What should I do if I need to work from home? ...   \n",
       "2         Emily Chen  If a close family member passes away, how many...   \n",
       "3     Marcus Jhonson  What happens if I report to work late multiple...   \n",
       "4  Jennifer Thompson  Can I accept gifts from clients or vendors, or...   \n",
       "\n",
       "   Agent Answer  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "excel_path = \"/home/user/RAG Course Enhaced/Docs/Questions.xlsx\"\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# Display first few rows\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5129c62",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü§ñ Step 10: Process All Questions\n",
    "\n",
    "### What are we doing here?\n",
    "\n",
    "This is where the magic happens! We'll go through EACH question and get an answer.üí° You'll see each question being processed in real-time.\n",
    "\n",
    "‚è±Ô∏è This will take some time depending on how many questions you have!\n",
    "\n",
    "**The process for each question:**\n",
    "\n",
    "1. üìñ Read the employee name and their question5. üìä Show progress as we go\n",
    "\n",
    "2. üîç RAG pipeline searches the documents4. ‚úçÔ∏è Save the answer in the Excel DataFrame\n",
    "3. ü§ñ AI generates an answer based on what it found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f38919d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 1/5: How many days of annual leave am I entitled to as ...\n",
      "Answer: As a full-time employee, you are entitled to an amount of annual leave based on your length of servi...\n",
      "\n",
      "Processing row 2/5: What should I do if I need to work from home? Is t...\n",
      "Answer: If you need to work from home, you should follow the proper procedures for requesting remote work ar...\n",
      "\n",
      "Processing row 3/5: If a close family member passes away, how many day...\n",
      "Answer: \n",
      "According to the provided context, if a close family member passes away, you may be eligible for up...\n",
      "\n",
      "Processing row 4/5: What happens if I report to work late multiple tim...\n",
      "Answer: If you report to work late multiple times, it may result in disciplinary action up to and including ...\n",
      "\n",
      "Processing row 5/5: Can I accept gifts from clients or vendors, or is ...\n",
      "Answer: \n",
      "According to the code of conduct policy provided in the context, it is not appropriate for employee...\n",
      "\n",
      "All questions processed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Worker</th>\n",
       "      <th>Question</th>\n",
       "      <th>Agent Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sarah Mitchell</td>\n",
       "      <td>How many days of annual leave am I entitled to...</td>\n",
       "      <td>As a full-time employee, you are entitled to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David Rodriguez</td>\n",
       "      <td>What should I do if I need to work from home? ...</td>\n",
       "      <td>If you need to work from home, you should foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emily Chen</td>\n",
       "      <td>If a close family member passes away, how many...</td>\n",
       "      <td>\\nAccording to the provided context, if a clos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marcus Jhonson</td>\n",
       "      <td>What happens if I report to work late multiple...</td>\n",
       "      <td>If you report to work late multiple times, it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jennifer Thompson</td>\n",
       "      <td>Can I accept gifts from clients or vendors, or...</td>\n",
       "      <td>\\nAccording to the code of conduct policy prov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Worker                                           Question  \\\n",
       "0     Sarah Mitchell  How many days of annual leave am I entitled to...   \n",
       "1    David Rodriguez  What should I do if I need to work from home? ...   \n",
       "2         Emily Chen  If a close family member passes away, how many...   \n",
       "3     Marcus Jhonson  What happens if I report to work late multiple...   \n",
       "4  Jennifer Thompson  Can I accept gifts from clients or vendors, or...   \n",
       "\n",
       "                                        Agent Answer  \n",
       "0  As a full-time employee, you are entitled to a...  \n",
       "1  If you need to work from home, you should foll...  \n",
       "2  \\nAccording to the provided context, if a clos...  \n",
       "3  If you report to work late multiple times, it ...  \n",
       "4  \\nAccording to the code of conduct policy prov...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'Agent Answer' column to string type\n",
    "df['Agent Answer'] = df['Agent Answer'].astype(str)\n",
    "\n",
    "# Iterate through each row and get answers\n",
    "for index, row in df.iterrows():\n",
    "    question = row['Question']\n",
    "    \n",
    "    print(f\"Processing row {index + 1}/{len(df)}: {question[:50]}...\")\n",
    "    \n",
    "    # Get answer from RAG pipeline\n",
    "    answer = rag_pipeline(question, vectorstore, client)\n",
    "    \n",
    "    # Save answer to the DataFrame\n",
    "    df.at[index, 'Agent Answer'] = answer\n",
    "    \n",
    "    print(f\"Answer: {answer[:100]}...\\n\")\n",
    "\n",
    "print(\"All questions processed!\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87249b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíæ Step 11: Save Results to Excel\n",
    "\n",
    "### What are we doing here?\n",
    "\n",
    "Time to save all our hard work! üéâ‚úÖ You can now open this file in Excel and review all the answers!\n",
    "\n",
    "\n",
    "\n",
    "**What happens:**You'll have a complete Excel file where Column C is filled with AI-generated answers to all the employee questions!\n",
    "\n",
    "1. Takes the DataFrame with all the questions AND answers**Result:**\n",
    "\n",
    "2. Saves it to a new Excel file: \"Questions_Answered.xlsx\"\n",
    "3. Shows a summary of how many responses were filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "707ce00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to /home/user/RAG Course Enhaced/Docs/Questions_Answered.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Save to a new Excel file\n",
    "output_path = \"/home/user/RAG Course Enhaced/Docs/Questions_Answered.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
